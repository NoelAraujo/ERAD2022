{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63a7f5c9",
   "metadata": {},
   "source": [
    "# Mini Curso de Otimização em Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8626eb9b",
   "metadata": {},
   "source": [
    "## Dica 1: Prepare seu Ambiente de Desenvolvimento \n",
    "\n",
    " Donald Knuth disse `Premature Optimization is the Root of All Evil`, essa afirmação é especialmente verdade quando você não sabe onde otimizar, e para isso o `VSCode` será seu aliado. \n",
    "\n",
    " As extensões recomendadas são: \n",
    " - `Julia Language Support`: Essencial\n",
    " - `Flame Chart Visualizer`: Profiler é gerado com essa extensão\n",
    " - `Fast Unicode Math Characters`: Para adicionar simbolos de vetores corretamente\n",
    " - `XT Color Theme`: Sugestão pessoal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed0d810",
   "metadata": {},
   "source": [
    "É recomendado que você *crie* ou *ative* o seu local de desenvolvimento. Para isso você precisa de um arquivo `Manifest.toml` dizendo a versão de todos os pacotes que estará utilizando. Isto é equivalente aos `Virtual Enviroments` do Conda.\n",
    "\n",
    "A [documentação](https://pkgdocs.julialang.org/v1/creating-packages/index.html) nos diz o caminho. Apenas os comandos são o suficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd9314c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Generating\u001b[22m\u001b[39m  project meuModulo:\n",
      "    meuModulo/Project.toml\n",
      "    meuModulo/src/meuModulo.jl\n",
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/ERAD2022/meuModulo`\n"
     ]
    }
   ],
   "source": [
    "import Pkg; \n",
    "Pkg.generate(\"ERAD2022\")\n",
    "cd(\"ERAD2022\")\n",
    "Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "234ae2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ERAD2022\n",
    "ERAD2022.greet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d791738",
   "metadata": {},
   "source": [
    "Esse esforço adicional para programar é útil quando você for criar programas mais longos, pois o seu `Módulo` poderá ser *escaneado* pelo pacote `Revise`, que irá recompilar as funções que você atualizar automaticamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde20a7",
   "metadata": {},
   "source": [
    "## Dica 2: Instale MKL.jl corretamente\n",
    "\n",
    "Computação científica faz forte uso de Algebra Linear, e por padrão, Julia vem com `OpenBlas` instalado. No entanto, sua concorrente direta é a biblioteca *intel MKL*, que é conhecida por ser mais rápida.  Após muito tempo no [Julia Discourse](https://discourse.julialang.org/) acredito que essa afirmação não é 100% correta, existem bibliotecas em Julia tão rapidas quando o MKL, ou ainda regimes no qual o OpenBlas é mais rápido. *Você terá que testar e descobrir se sua aplicação é mais rápida com MKL*.\n",
    "\n",
    "A partir da *versão v1.7* a instalação do MKL é muito prática:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15e0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg; Pkg.add(\"MKL\")\n",
    "Pkg.status(\"MKL\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d6061d",
   "metadata": {},
   "source": [
    "**CONTUDO:** **No Linux**, ainda é necessário configurar as variáveis do ambiente para fazer uso adequado do multithreading. Como MKL faz uso de `OpenMP`, você tem que informar quantas threads serão utilizadas definindo a variável de sistema `OMP_NUM_THREADS`. O melhor desempenho acontece quando numero de threads é igual ao número de processadores **fisicos**. Contudo, essa flag não permite Julia utilizar todas as threads disponiveis, por isso você precisa exportar a flag `JULIA_NUM_THREADS` seperadamente.\n",
    "\n",
    "Meu computador possui 4 Cores e 8 Threads, então eu declaro as variaveis no arquivo `~/.bashrc`:\n",
    "```\n",
    "export JULIA_NUM_THREADS=8\n",
    "export OMP_NUM_THREADS=4\n",
    "```\n",
    "\n",
    "Nos meus testes, não tive variação de desempenho no Windows.\n",
    "\n",
    "Agora, você pode inicie Julia novamente, e execute `using MKL`. A seguir, testaremos o desempenho do OpenBlas contra MKL para diferentes tamanhos de matrizes. Caso não tenha instalado, adicione o pacote `Plots`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e02a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg; Pkg.add([\"Plots\", \"Random\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e1aded",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra, Random, Plots\n",
    "\n",
    "\"\"\"\n",
    "    resolver sistemas de equações lineares (Ax=b)\n",
    "\"\"\"\n",
    "function testandoMKL(N)\n",
    "    A = rand(N, N)\n",
    "    b = rand(N)\n",
    "    x = @elapsed  A\\b\n",
    "    return x\n",
    "end\n",
    "testandoMKL(5) # warm up\n",
    "testandoMKL(10) # warm up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b547e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_em_escala_log = round.(Int, 10.0.^range(2, 3, length=100))\n",
    "\n",
    "Random.seed!(2022)\n",
    "t_openblas = Float64[]\n",
    "@show BLAS.get_config() # verificar que é o OpenBLAS\n",
    "for N = N_em_escala_log\n",
    "    push!(t_openblas, testandoMKL(N))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81685ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MKL # agora o MKL vai funcionar\n",
    "Random.seed!(2022)\n",
    "t_mkl = Float64[]\n",
    "@show BLAS.get_config()\n",
    "for N = N_em_escala_log\n",
    "    push!(t_mkl, testandoMKL(N))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c801c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(N_em_escala_log, t_openblas,label=\"OpenBlas\", markershape=:square, legend=:topleft)\n",
    "plot!(N_em_escala_log, t_mkl,label=\"MKL\", scale=:log10, markershape=:circle)\n",
    "xlabel!(\"N\")\n",
    "ylabel!(\"tempo [s]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db27ab42",
   "metadata": {},
   "source": [
    "## Dica 3: Declare os Tipos\n",
    " \n",
    " Julia tem otimizações automáticas e elas são mais efetivas quando os *tipos* dos objetos são bem definidos. Dê preferência a `Arrays` e `Structs`, e evite `Dict`. A seguir alguns exemplos de fixação:\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735485de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `a` é Array que pode conter qualquer objeto, por isso, seu tipo é 'Any'.\n",
    "a = []\n",
    "push!(a, 2)\n",
    "push!(a, 3.0)\n",
    "println(\"Tipo de a: \", typeof(a))\n",
    "\n",
    "# Se temos certeza que iremos armazenar apenas valores do tipo `Float64`, basta declará-lo antes do `[]`.\n",
    "b = Float64[]\n",
    "push!(b, 2) # Julia fará a conversão de `2` para `2.0`\n",
    "push!(b, 3)\n",
    "println(\"Tipo de b: \",typeof(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a91a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "push!(a, 4 + 5im) # funciona\n",
    "@show a;\n",
    "println(\"-------\")\n",
    "try\n",
    "    push!(b, 4 + 5im) # não funciona\n",
    "catch\n",
    "    println(\"Não existe conversão de Float para Complex.\")\n",
    "    @show b\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce15c314",
   "metadata": {},
   "source": [
    "*structs* são fáceis de criar, e aqui trago um alerta. Use *immutable structs* sempre que possível. Isso permitirá ao otimizador de Julia fazer seu serviço de forma mais eficiente, já que os tipos não mudam. \n",
    "\n",
    "A otimização com `struct` mais interessante é alocar dados na memória *stack* e não na *heap*. Para você não se preocupar em como fazer isso, já existe o pacote `StaticArrays`.   \n",
    "Importante: esse pacote só é útil para vetores ou matrizes pequenos - 'pequeno' depende do contexto, o mais comum é armazenar coordenadas (x,y,z)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d1ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add([\"StaticArrays\", \"BenchmarkTools\"])\n",
    "using StaticArrays, BenchmarkTools\n",
    "\n",
    "v_default = [[i^2, i^3, 4i] for i = 1:1000]\n",
    "v_static =  [@SVector [i^2, i^3, 4i] for i = 1:1000]\n",
    "\n",
    "@btime sum.(v_default)\n",
    "@btime sum.(v_static);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a7a595",
   "metadata": {},
   "source": [
    "Outro problema comum é que Julia pode ficar indeciso sobre qual tipo será utilizado, é o famoso **type instability problem**.  Recomendo o post [Writing type-stable Julia code](https://www.juliabloggers.com/writing-type-stable-julia-code) ou [Type instability and performance](https://m3g.github.io/JuliaNotes.jl/stable/instability/). \n",
    "\n",
    "Na prática, minha dica é usar `typeof` sempre que possível, o caso mais recorrente é a inicialização de contadores. No lugar de escrever `u = 0` ou `u = 0.0`, permita que Julia crie a variável do tipo adequada, usando a função  `zero`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f473bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = rand(ComplexF32, 10)\n",
    "\n",
    "# Não faço isso, mesmo estando correto\n",
    "u_sum = 0f0 + 0f0*im\n",
    "u_vec = ComplexF32[]\n",
    "\n",
    "# Faça isso. Assim seu código é genérico\n",
    "u_sum = zero( eltype(v) ) # == zero(ComplexF32) == 0.f0 + 0.f0im\n",
    "u_vec = eltype(v)[] # Array do tipo ComplexF32\n",
    "\n",
    "for vv in v\n",
    "    u_sum += vv\n",
    "    push!( u_vec, 2*vv)\n",
    "end\n",
    "@show u_sum\n",
    "@show u_vec;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8776f9ce",
   "metadata": {},
   "source": [
    "## Dica 4: Faça o Benchmark corretamente\n",
    "\n",
    "O que não falta na internet são posts de pessoas dizendo que seus código em Julia estão lentos, e logo em seguida, alguém aponta que o processo de medição esta incorreto. \n",
    "\n",
    "O tempo de um código em Julia é composto do **Tempo de Compilação** e o **Tempo de Execução**. O tempo predominante depende muito do código e da escala do problema. O que você realmente quer medir, é o Tempo de Execução, e isso não é possivel de fazer usando a função `time` no Bash do Linux (se você fizer isso, irá medir ambos os tempos). A solução é:\n",
    "- Crie seu código\n",
    "- Faça um *aquecimento*: execute ele 1 vez, porém com parâmetros pequenos, apenas para gerar o código de máquina\n",
    "- Execute novamente seu código, com parâmetro realisticos, e meça o tempo de execução\n",
    "    - Se o tempo for na ordem de segundos, use a macro `@elapsed`\n",
    "    - Se o tempo for curto, utilize um pacote especializado chamado `BenchmarkTools`. Com ele, use a macro `@belapsed`, e não esqueça de usar `$` na chamada de função\n",
    "- Salve o tempo de execução em um arquivo, ou exiba na tela\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b1227",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rand(8_000_000)\n",
    "tempo1 = @elapsed sum(x);\n",
    "\n",
    "\n",
    "using BenchmarkTools\n",
    "tempo2 = @belapsed sum($x);\n",
    "\n",
    "@show tempo1, tempo2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7206a675",
   "metadata": {},
   "source": [
    "Caso esteja programando de forma interativa, vale a pena conferir quanta memória esta sendo alocada usando `@time` - normalmente, quanto menos memória, melhor. Entretando, é mais relevante você ter uma ideia completa do tempo de execução, e para isso `BenchmarkTools` exporta a função `@benchmark`. Nela você vai reparar que o tempo emitido pelo `@belapsed` foi o tempo minimo entre várias repetições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark sum($x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f50958c",
   "metadata": {},
   "source": [
    "## Dica 5: Crie Funções\n",
    "\n",
    "Na *Dica 2* eu fiz questão de criar a função `testandoMKL` para medir o tempo de execução, e isso não foi uma conveniência ou estética para os meus códigos. O *Escopo Global* (seu REPL) de Julia precisa garantir que seus códigos funcionem ao custo de não garantir os tipos - tipos genéricos `Any` não têm muitas otimizações. \n",
    "\n",
    "**A solução é simples: Crie Funções**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc14fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time begin\n",
    "    N = 1_000\n",
    "    A = zeros(N,N)\n",
    "    for m=1:N\n",
    "        for n=1:N\n",
    "            A[n,m] = rand(eltype(A))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function criei_função()\n",
    "    N = 1_000\n",
    "    A = zeros(N,N)\n",
    "    for m=1:N\n",
    "        for n=1:N\n",
    "            A[n,m] = rand(eltype(A))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "@time criei_função()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d30dc4",
   "metadata": {},
   "source": [
    "Claro que criar funções em todos os lugares nem sempre é a melhor solução, e você gostaria que o compilador fizesse `inline expansion`. Você pode indicar isso manualmente para o compilador colocando a macro `@inline` antes da declaração da função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b72129",
   "metadata": {},
   "outputs": [],
   "source": [
    "@inline function calculoPrincipal()\n",
    "    # fazer algo\n",
    "end\n",
    "\n",
    "function funçãoPrincipal()\n",
    "    for i=1:N\n",
    "        calculoPrincipal()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a775344a",
   "metadata": {},
   "source": [
    "# Projetos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc40e393",
   "metadata": {},
   "source": [
    "# Projeto 1: Transcrição Python em Julia\n",
    "\n",
    "Agradecimentos ao Edmilson Roque (Cris), ICMC-USP por fornecer o código.\n",
    "\n",
    "Faremos uma conversão de código que realiza Processo de Ortogonalização de Gram-Schmidt, cujos vetores são `Funções`, e não `Arrays`. \n",
    "\n",
    "O código original faz uso de recursividade e funções anônimas (função lambda). Essas grande quantidade de chamadas de funções será contornada com Memoização e Cálculo Simbólico.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8131c9",
   "metadata": {},
   "source": [
    "# Projeto 2: Evolução de EDOs\n",
    "\n",
    "Faremos a evolução temporal do conjunto de equações diferencais que representam a excitação de estado atômicos\n",
    "$$ \\frac{d\\beta_j}{dt} = \\left( iΔ - \\frac{\\Gamma}{2}\\right )\\beta_j + \\frac{i\\Omega_j}{2}z_j - z_j\\sum_{m ≠ j}^N G_{j,m}\\beta_m$$\n",
    "$$ \\frac{dz_j}{dt} = [i\\Omega_j ^\\dagger\\beta_j - i\\Omega_j\\beta_j ^\\dagger] - \\Gamma (1+z_j) + \\frac{2}{\\Gamma}\\sum_{j≠ m}^N G_{j,m}\\beta_m \\beta_j^\\dagger$$\n",
    "\n",
    "Com $\\Gamma=1$, $G = -\\frac{\\Gamma}{2}exp(-ir_{jm})/ir_{jm}$ e condição inicial $\\beta_0 = 0$ e $z_0 = -1$\n",
    "\n",
    "\n",
    "Algumas otimizações não são limitadas a Julia, mas são educativas para o público geral. Nesse projeto desejamos evitar alocação de memória (variáveis temporárias) com @views e multiplicação matricial. Além disso, poderemos dar nosso primeiro código em GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48c3260",
   "metadata": {},
   "source": [
    "# Projeto 3: Somatória Dupla\n",
    "\n",
    "Uma vez que calcumos os estados atômicos, $\\beta_n$, do projeto anterior, uma pergunta natural é descobrir qual a intesidade da luz emitida em certa direção do espaço $\\hat{n}$. Para esse projeto, a intensidade será calculada pela fórmula \n",
    "\n",
    "$$ I = \\sum_n^N \\sum_{m ≠ n}^N \\beta_n^† \\beta_m e^{i\\; \\hat{n}⋅(\\vec{r}_n - \\vec{r}_m) } $$\n",
    "\n",
    "$\\vec{r}_n$ é a posição do emissor em coordenadas cartesianas.\n",
    "\n",
    "Essa somatória dupla possui muito espaço para otimização ao evitar operações desnecessárias, além de ser o caso ideal para multithreading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409fc481",
   "metadata": {},
   "source": [
    "# Projeto 4: Processamento de Imagem\n",
    "\n",
    "Implementaremos um algoritmo muito simples para detecção de bordas em imagens. \n",
    "- Analisaremos uma figura pixel-a-pixel, e comparamos a intensidade de cor (média dos canais R,G,B) do pixel atual, com um pixel a esquerda e um pixel inferior.   \n",
    "    - Se a diferença de valores entre os 3 pontos for maior que um threshold definido pelo usuário (que dependa da imagem)\n",
    "        - nós pintamos o pixel da borda com uma cor escura\n",
    "    - Senão for uma borda, deixamos como cor branca\n",
    "\n",
    "\n",
    "Esse algoritmo é Vergonhosamento Paralelo, e por isso vamos usar o paralelismo nativo de Julia para aprender algumas ferramentas básicas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
